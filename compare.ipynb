{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np # Import numpy\n",
    "try:\n",
    "    from tqdm.auto import tqdm  # For progress bars\n",
    "    TQDM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TQDM_AVAILABLE = False\n",
    "    print(\"Warning: tqdm library not found. Progress bars will not be shown. To enable them, please install tqdm: pip install tqdm\")\n",
    "    # Define a dummy tqdm if not available so the code doesn't break\n",
    "    def tqdm(iterable, *args, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "\n",
    "# Cell 2: Load the Excel files\n",
    "# Replace 'extract.xlsx' and 'gold.xlsx' with the actual file paths\n",
    "try:\n",
    "    df_extract = pd.read_excel('extract.xlsx')\n",
    "    df_gold = pd.read_excel('gold.xlsx')\n",
    "    print(\"Successfully loaded 'extract.xlsx' and 'gold.xlsx'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"One or both Excel files not found. Using dummy data for demonstration.\")\n",
    "    # Create dummy dataframes for demonstration if files are not found\n",
    "    data_extract = {\n",
    "        'filepath': ['/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/2510600056001201252_f.jpeg',\n",
    "                     '/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/1234567890123456789_f.jpeg',\n",
    "                     '/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/9999999999999999999_f.jpeg',\n",
    "                     '/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/0000000000000000000_f.jpeg'], # Added a no-match record\n",
    "        'payee_name': ['John Doe!', 'Jane Smith.', 'Another Person', 'No Match Name'],\n",
    "        'amount_numeric': [750, 1200.50, 500, 100],\n",
    "        'micr_code': ['123456CITYBANKBRANCH001SAVINGS', '987654CITY2BANK2BRANCH2002CURRENT', '111222CITY3BANK3BRANCH3003SAVINGS', 'NOMATCHMICR']\n",
    "    }\n",
    "    df_extract = pd.DataFrame(data_extract)\n",
    "\n",
    "    data_gold = {\n",
    "        'TRANSACTION_DATE': ['16/04/2025', '17/04/2025', '18/04/2025'],\n",
    "        'INSTRUMENT_ID': [2510600056001201252, 9876543210987654321, 9999999999999999999],\n",
    "        'FLOW_TYPE': ['INWARD', 'OUTWARD', 'INWARD'],\n",
    "        'SCAN_INSTRUMENT_NUMBER': [123456, 987654, 111222],\n",
    "        'SCAN_PAYEE_BANK_CITY_CODE': ['CITY', 'CITY2', 'CITY3'],\n",
    "        'SCAN_PAYEE_BANK_CODE': ['BANK', 'BANK2', 'BANK3'],\n",
    "        'SCAN_PAYEE_BANK_BRANCH_CODE': ['BRANCH', 'BRANCH2', 'BRANCH3'],\n",
    "        'SCAN_MICR_ACNO': [1, 0, 3],\n",
    "        'SCAN_INSTRUMENT_TYPE': ['SAVINGS', 'CURRENT', 'SAVINGS'],\n",
    "        'PRES_NAME': [' John Doe ', 'Jane  Smith', 'Another Person '],\n",
    "        'CAR_AMOUNT': [750.00, 1250.00, 500.00]\n",
    "    }\n",
    "    df_gold = pd.DataFrame(data_gold)\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "print(\"\\nExcel 1 (Extract) Head:\")\n",
    "print(df_extract.head())\n",
    "print(\"\\nExcel 2 (Gold) Head:\")\n",
    "print(df_gold.head())\n",
    "\n",
    "# Cell 3: Preprocess df_extract\n",
    "# Extract INSTRUMENT_ID from filepath\n",
    "def extract_instrument_id(filepath):\n",
    "    if pd.isna(filepath):\n",
    "        return None\n",
    "    match = re.search(r'/([^/]+)_f\\.jpeg$', str(filepath))\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = df_extract['filepath'].apply(extract_instrument_id)\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = pd.to_numeric(df_extract['INSTRUMENT_ID_EXTRACT'], errors='coerce')\n",
    "\n",
    "print(\"\\nDF Extract after INSTRUMENT_ID extraction:\")\n",
    "print(df_extract.head())\n",
    "\n",
    "# Cell 4: Preprocess df_gold\n",
    "# Construct micr_code in df_gold\n",
    "def construct_micr(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['SCAN_INSTRUMENT_NUMBER']):\n",
    "        parts.append(str(row['SCAN_INSTRUMENT_NUMBER']))\n",
    "    if pd.notna(row['SCAN_PAYEE_BANK_CITY_CODE']):\n",
    "        parts.append(str(row['SCAN_PAYEE_BANK_CITY_CODE']))\n",
    "    if pd.notna(row['SCAN_PAYEE_BANK_CODE']):\n",
    "        parts.append(str(row['SCAN_PAYEE_BANK_CODE']))\n",
    "    if pd.notna(row['SCAN_PAYEE_BANK_BRANCH_CODE']):\n",
    "        parts.append(str(row['SCAN_PAYEE_BANK_BRANCH_CODE']))\n",
    "    if pd.notna(row['SCAN_MICR_ACNO']) and row['SCAN_MICR_ACNO'] != 0:\n",
    "        parts.append(str(int(row['SCAN_MICR_ACNO'])))\n",
    "    if pd.notna(row['SCAN_INSTRUMENT_TYPE']):\n",
    "        parts.append(str(row['SCAN_INSTRUMENT_TYPE']))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "df_gold['micr_code_gold'] = df_gold.apply(construct_micr, axis=1)\n",
    "df_gold['INSTRUMENT_ID'] = pd.to_numeric(df_gold['INSTRUMENT_ID'], errors='coerce')\n",
    "\n",
    "print(\"\\nDF Gold after micr_code_gold construction:\")\n",
    "print(df_gold.head())\n",
    "\n",
    "# Cell 5: Merge the DataFrames\n",
    "df_merged = pd.merge(df_extract, df_gold, left_on='INSTRUMENT_ID_EXTRACT', right_on='INSTRUMENT_ID', how='left', suffixes=('_extract', '_gold'))\n",
    "\n",
    "print(\"\\nMerged DataFrame Head:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# Cell 6: Define comparison functions\n",
    "def compare_names(name1, name2):\n",
    "    if pd.isna(name1) or pd.isna(name2):\n",
    "        return False, \"One or both names are NaN\"\n",
    "    norm_name1 = str(name1).strip().lower()\n",
    "    norm_name2 = str(name2).strip().lower()\n",
    "    norm_name1 = re.sub(r'[^a-z0-9\\s]', '', norm_name1)\n",
    "    norm_name2 = re.sub(r'[^a-z0-9\\s]', '', norm_name2)\n",
    "    norm_name1 = re.sub(r'\\s+', ' ', norm_name1).strip()\n",
    "    norm_name2 = re.sub(r'\\s+', ' ', norm_name2).strip()\n",
    "    return norm_name1 == norm_name2, f\"Normalized Extract: '{norm_name1}', Normalized Gold: '{norm_name2}'\"\n",
    "\n",
    "def compare_amounts(amount1, amount2):\n",
    "    if pd.isna(amount1) or pd.isna(amount2):\n",
    "        return False\n",
    "    try:\n",
    "        return float(amount1) == float(amount2)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def compare_micr(micr1, micr2):\n",
    "    if pd.isna(micr1) or pd.isna(micr2):\n",
    "        return False\n",
    "    return str(micr1).strip() == str(micr2).strip()\n",
    "\n",
    "# Cell 7: Apply comparison functions and calculate match scores\n",
    "if TQDM_AVAILABLE:\n",
    "    tqdm.pandas(desc=\"Processing records for comparison\") \n",
    "\n",
    "df_merged['payee_name_match_status'] = False\n",
    "df_merged['payee_name_match_details'] = ''\n",
    "df_merged['amount_match_status'] = False\n",
    "df_merged['micr_match_status'] = False\n",
    "df_merged['fields_matched'] = 0\n",
    "\n",
    "print(\"\\nApplying comparisons:\")\n",
    "# Use tqdm directly on iterrows\n",
    "for index, row in tqdm(df_merged.iterrows(), total=df_merged.shape[0], desc=\"Comparing records\"):\n",
    "    current_matches = 0\n",
    "    # Compare Payee Name\n",
    "    if 'payee_name' in df_merged.columns and 'PRES_NAME' in df_merged.columns:\n",
    "        if pd.notna(row['payee_name']) and pd.notna(row['PRES_NAME']):\n",
    "            name_match_result, name_match_detail_str = compare_names(row['payee_name'], row['PRES_NAME'])\n",
    "            df_merged.loc[index, 'payee_name_match_status'] = name_match_result\n",
    "            df_merged.loc[index, 'payee_name_match_details'] = name_match_detail_str\n",
    "            if name_match_result:\n",
    "                current_matches += 1\n",
    "        else:\n",
    "             df_merged.loc[index, 'payee_name_match_details'] = \"One or both names missing for comparison\"\n",
    "    else:\n",
    "        df_merged.loc[index, 'payee_name_match_details'] = \"Payee name columns not found\"\n",
    "\n",
    "    # Compare Amount\n",
    "    if 'amount_numeric' in df_merged.columns and 'CAR_AMOUNT' in df_merged.columns:\n",
    "        if pd.notna(row['amount_numeric']) and pd.notna(row['CAR_AMOUNT']):\n",
    "            amount_match_result = compare_amounts(row['amount_numeric'], row['CAR_AMOUNT'])\n",
    "            df_merged.loc[index, 'amount_match_status'] = amount_match_result\n",
    "            if amount_match_result:\n",
    "                current_matches += 1\n",
    "    \n",
    "    # Compare MICR\n",
    "    if 'micr_code' in df_merged.columns and 'micr_code_gold' in df_merged.columns:\n",
    "        if pd.notna(row['micr_code']) and pd.notna(row['micr_code_gold']):\n",
    "            micr_match_result = compare_micr(row['micr_code'], row['micr_code_gold'])\n",
    "            df_merged.loc[index, 'micr_match_status'] = micr_match_result\n",
    "            if micr_match_result:\n",
    "                current_matches += 1\n",
    "    df_merged.loc[index, 'fields_matched'] = current_matches\n",
    "\n",
    "fields_to_compare_list = []\n",
    "for index, row in df_merged.iterrows():\n",
    "    count = 0\n",
    "    if 'payee_name' in df_merged.columns and 'PRES_NAME' in df_merged.columns and \\\n",
    "       pd.notna(row['payee_name']) and pd.notna(row['PRES_NAME']):\n",
    "        count += 1\n",
    "    if 'amount_numeric' in df_merged.columns and 'CAR_AMOUNT' in df_merged.columns and \\\n",
    "       pd.notna(row['amount_numeric']) and pd.notna(row['CAR_AMOUNT']):\n",
    "        count += 1\n",
    "    if 'micr_code' in df_merged.columns and 'micr_code_gold' in df_merged.columns and \\\n",
    "       pd.notna(row['micr_code']) and pd.notna(row['micr_code_gold']):\n",
    "        count += 1\n",
    "    fields_to_compare_list.append(count)\n",
    "df_merged['fields_to_compare'] = fields_to_compare_list\n",
    "\n",
    "# Calculate match percentage using np.where to avoid division by zero issues and recursion\n",
    "df_merged['match_percentage'] = np.where(\n",
    "    df_merged['fields_to_compare'] > 0,\n",
    "    (df_merged['fields_matched'] / df_merged['fields_to_compare']) * 100,\n",
    "    0  # Set to 0 if fields_to_compare is 0\n",
    ")\n",
    "df_merged['match_percentage'] = df_merged['match_percentage'].fillna(0) # Ensure any other NaNs become 0\n",
    "\n",
    "\n",
    "print(\"\\nDataFrame with Match Status and Percentage:\")\n",
    "print(df_merged[['INSTRUMENT_ID_EXTRACT', 'payee_name_match_status', 'amount_match_status', 'micr_match_status',\n",
    "                 'fields_matched', 'fields_to_compare', 'match_percentage']].head())\n",
    "\n",
    "# Cell 8: Select relevant columns for the output and save to Excel\n",
    "output_columns = [\n",
    "    'filepath', 'INSTRUMENT_ID_EXTRACT', 'payee_name', 'amount_numeric', 'micr_code', \n",
    "    'INSTRUMENT_ID', 'PRES_NAME', 'CAR_AMOUNT', 'micr_code_gold', \n",
    "    'SCAN_INSTRUMENT_NUMBER', 'SCAN_PAYEE_BANK_CITY_CODE', 'SCAN_PAYEE_BANK_CODE', \n",
    "    'SCAN_PAYEE_BANK_BRANCH_CODE', 'SCAN_MICR_ACNO', 'SCAN_INSTRUMENT_TYPE', \n",
    "    'payee_name_match_status', 'payee_name_match_details', 'amount_match_status', 'micr_match_status', \n",
    "    'fields_matched', 'fields_to_compare', 'match_percentage' \n",
    "]\n",
    "\n",
    "final_output_columns = [col for col in output_columns if col in df_merged.columns]\n",
    "df_output = df_merged[final_output_columns]\n",
    "\n",
    "try:\n",
    "    output_file_name = 'comparison_results_final.xlsx'\n",
    "    df_output.to_excel(output_file_name, index=False)\n",
    "    print(f\"\\nComparison results saved to '{output_file_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to Excel: {e}\")\n",
    "\n",
    "# Cell 9: Display overall statistics (optional)\n",
    "total_records = len(df_merged)\n",
    "# For perfect matches, consider only rows where there was something to compare\n",
    "perfect_matches_df = df_merged[df_merged['fields_to_compare'] > 0]\n",
    "perfect_matches = len(perfect_matches_df[perfect_matches_df['match_percentage'] == 100])\n",
    "\n",
    "overall_field_matches_sum = df_merged['fields_matched'].sum()\n",
    "overall_fields_to_compare_sum = df_merged['fields_to_compare'].sum()\n",
    "\n",
    "overall_match_accuracy = (overall_field_matches_sum / overall_fields_to_compare_sum * 100) if overall_fields_to_compare_sum > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Overall Statistics ---\")\n",
    "print(f\"Total Records Processed: {total_records}\")\n",
    "print(f\"Records with 100% Match (among comparable): {perfect_matches}\")\n",
    "\n",
    "if overall_fields_to_compare_sum > 0:\n",
    "    print(f\"Overall Field Match Accuracy: {overall_match_accuracy:.2f}% ({overall_field_matches_sum}/{overall_fields_to_compare_sum} fields)\")\n",
    "else:\n",
    "    print(\"Overall Field Match Accuracy: Not applicable (no fields to compare or all comparable fields were NaN)\")\n",
    "\n",
    "if 'payee_name_match_status' in df_merged.columns:\n",
    "    name_matches = df_merged['payee_name_match_status'].sum()\n",
    "    name_total_comparable = len(df_merged[df_merged['payee_name'].notna() & df_merged['PRES_NAME'].notna()])\n",
    "    name_accuracy = (name_matches / name_total_comparable * 100) if name_total_comparable > 0 else 0\n",
    "    print(f\"Payee Name Match Accuracy: {name_accuracy:.2f}% ({name_matches}/{name_total_comparable} comparable pairs)\")\n",
    "\n",
    "if 'amount_match_status' in df_merged.columns:\n",
    "    amount_matches = df_merged['amount_match_status'].sum()\n",
    "    amount_total_comparable = len(df_merged[df_merged['amount_numeric'].notna() & df_merged['CAR_AMOUNT'].notna()])\n",
    "    amount_accuracy = (amount_matches / amount_total_comparable * 100) if amount_total_comparable > 0 else 0\n",
    "    print(f\"Amount Match Accuracy: {amount_accuracy:.2f}% ({amount_matches}/{amount_total_comparable} comparable pairs)\")\n",
    "\n",
    "if 'micr_match_status' in df_merged.columns:\n",
    "    micr_matches = df_merged['micr_match_status'].sum()\n",
    "    micr_total_comparable = len(df_merged[df_merged['micr_code'].notna() & df_merged['micr_code_gold'].notna()])\n",
    "    micr_accuracy = (micr_matches / micr_total_comparable * 100) if micr_total_comparable > 0 else 0\n",
    "    print(f\"MICR Code Match Accuracy: {micr_accuracy:.2f}% ({micr_matches}/{micr_total_comparable} comparable pairs)\")\n",
    "\n",
    "print(\"--- End of Notebook ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd734dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np # Import numpy\n",
    "try:\n",
    "    from tqdm.auto import tqdm  # For progress bars\n",
    "    tqdm.pandas() # Initialize tqdm for pandas functions like progress_apply\n",
    "    TQDM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TQDM_AVAILABLE = False\n",
    "    print(\"Warning: tqdm library not found. Progress bars for apply functions will not be shown. To enable them, please install tqdm: pip install tqdm\")\n",
    "    # Define a dummy tqdm if not available so the code doesn't break\n",
    "    def tqdm(iterable, *args, **kwargs): # This dummy is for iterables\n",
    "        return iterable\n",
    "    # If tqdm.pandas() can't be called, progress_apply will just be apply\n",
    "    # We can create a dummy progress_apply if needed, or let it default to apply\n",
    "    # For simplicity, if tqdm is not there, progress_apply will become a direct apply call later\n",
    "\n",
    "# Cell 2: Load the Excel files\n",
    "# Replace 'extract.xlsx' and 'gold.xlsx' with the actual file paths\n",
    "try:\n",
    "    df_extract = pd.read_excel('extract.xlsx')\n",
    "    df_gold = pd.read_excel('gold.xlsx')\n",
    "    print(\"Successfully loaded 'extract.xlsx' and 'gold.xlsx'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"One or both Excel files not found. Using dummy data for demonstration (30k rows).\")\n",
    "    # Create larger dummy dataframes for demonstration\n",
    "    num_records = 30000\n",
    "    base_instrument_id = 2510600056001201252\n",
    "    data_extract = {\n",
    "        'filepath': [f'/tmp/job/path/to/{base_instrument_id + i}_f.jpeg' for i in range(num_records)],\n",
    "        'payee_name': [f'Payee Name {i % 100}!' if i % 2 == 0 else f' Payee Name {i % 100} ' for i in range(num_records)],\n",
    "        'amount_numeric': [750 + (i%1000) if i % 2 == 0 else (750 + (i%1000)) * 1.0 for i in range(num_records)],\n",
    "        'micr_code': [f'123456CITYBANKBRANCH00{i%10}SAVINGS' if i%3==0 else f'654321CITYBANKALT0{i%5}CURRENT' for i in range(num_records)]\n",
    "    }\n",
    "    df_extract = pd.DataFrame(data_extract)\n",
    "    # Add some NaNs for testing robustness\n",
    "    for col in ['payee_name', 'amount_numeric', 'micr_code']:\n",
    "      df_extract.loc[df_extract.sample(frac=0.05).index, col] = np.nan\n",
    "\n",
    "\n",
    "    data_gold = {\n",
    "        'TRANSACTION_DATE': [f'{(i%28)+1}/{(i%12)+1}/2025' for i in range(num_records)],\n",
    "        'INSTRUMENT_ID': [base_instrument_id + i for i in range(num_records)],\n",
    "        'FLOW_TYPE': ['INWARD' if i % 2 == 0 else 'OUTWARD' for i in range(num_records)],\n",
    "        'SCAN_INSTRUMENT_NUMBER': [123456 + i for i in range(num_records)],\n",
    "        'SCAN_PAYEE_BANK_CITY_CODE': ['CITY' if i%2==0 else 'CITYALT' for i in range(num_records)],\n",
    "        'SCAN_PAYEE_BANK_CODE': ['BANK' for i in range(num_records)],\n",
    "        'SCAN_PAYEE_BANK_BRANCH_CODE': ['BRANCH' if i%2==0 else 'BRANCHALT' for i in range(num_records)],\n",
    "        'SCAN_MICR_ACNO': [i % 5 if (i % 5 != 0) else (0 if i%10==0 else np.nan) for i in range(num_records)], # include 0 and NaN\n",
    "        'SCAN_INSTRUMENT_TYPE': ['SAVINGS' if i%3==0 else 'CURRENT' for i in range(num_records)],\n",
    "        'PRES_NAME': [f'Payee Name {i % 100}' for i in range(num_records)], # Gold standard names\n",
    "        'CAR_AMOUNT': [750 + (i%1000) for i in range(num_records)]\n",
    "    }\n",
    "    df_gold = pd.DataFrame(data_gold)\n",
    "    # Add some NaNs for testing robustness\n",
    "    for col in ['PRES_NAME', 'CAR_AMOUNT', 'SCAN_MICR_ACNO']:\n",
    "      df_gold.loc[df_gold.sample(frac=0.05).index, col] = np.nan\n",
    "\n",
    "\n",
    "print(f\"\\nExcel 1 (Extract) Head ({len(df_extract)} rows):\")\n",
    "print(df_extract.head())\n",
    "print(f\"\\nExcel 2 (Gold) Head ({len(df_gold)} rows):\")\n",
    "print(df_gold.head())\n",
    "\n",
    "# Cell 3: Preprocess df_extract (Vectorized where possible)\n",
    "print(\"\\nPreprocessing df_extract...\")\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = df_extract['filepath'].astype(str).str.extract(r'/([^/]+)_f\\.jpeg$')[0]\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = pd.to_numeric(df_extract['INSTRUMENT_ID_EXTRACT'], errors='coerce')\n",
    "print(\"DF Extract after INSTRUMENT_ID extraction head:\")\n",
    "print(df_extract.head())\n",
    "\n",
    "# Cell 4: Preprocess df_gold (Vectorized MICR construction)\n",
    "print(\"\\nPreprocessing df_gold (vectorized MICR)...\")\n",
    "\n",
    "# Convert components to string, filling NaNs with empty strings\n",
    "s_instr_num = df_gold['SCAN_INSTRUMENT_NUMBER'].fillna('').astype(str)\n",
    "s_city = df_gold['SCAN_PAYEE_BANK_CITY_CODE'].fillna('').astype(str)\n",
    "s_bank = df_gold['SCAN_PAYEE_BANK_CODE'].fillna('').astype(str)\n",
    "s_branch = df_gold['SCAN_PAYEE_BANK_BRANCH_CODE'].fillna('').astype(str)\n",
    "s_instr_type = df_gold['SCAN_INSTRUMENT_TYPE'].fillna('').astype(str)\n",
    "\n",
    "# Conditional SCAN_MICR_ACNO\n",
    "# Ensure it's numeric before comparison, then convert to int string, or empty\n",
    "micr_acno_num = pd.to_numeric(df_gold['SCAN_MICR_ACNO'], errors='coerce')\n",
    "s_micr_acno = np.where(\n",
    "    (micr_acno_num.notna()) & (micr_acno_num != 0),\n",
    "    micr_acno_num.astype(float).astype(int).astype(str), # astype(float) handles cases like \"1.0\" before int\n",
    "    ''\n",
    ")\n",
    "df_gold['micr_code_gold'] = s_instr_num + s_city + s_bank + s_branch + s_micr_acno + s_instr_type\n",
    "df_gold['INSTRUMENT_ID'] = pd.to_numeric(df_gold['INSTRUMENT_ID'], errors='coerce')\n",
    "print(\"DF Gold after micr_code_gold construction head:\")\n",
    "print(df_gold[['INSTRUMENT_ID', 'micr_code_gold']].head())\n",
    "\n",
    "# Cell 5: Merge the DataFrames\n",
    "print(\"\\nMerging DataFrames...\")\n",
    "df_merged = pd.merge(df_extract, df_gold, left_on='INSTRUMENT_ID_EXTRACT', right_on='INSTRUMENT_ID', how='left', suffixes=('_extract', '_gold'))\n",
    "print(f\"Merged DataFrame shape: {df_merged.shape}\")\n",
    "print(\"Merged DataFrame Head:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# Cell 6: Comparison logic (will be applied vectorially in Cell 7)\n",
    "# Normalization function for names (can be applied to series)\n",
    "def normalize_name_series(name_series):\n",
    "    if not isinstance(name_series, pd.Series):\n",
    "        name_series = pd.Series(name_series)\n",
    "    norm_s = name_series.astype(str).str.strip().str.lower()\n",
    "    norm_s = norm_s.str.replace(r'[^a-z0-9\\s]', '', regex=True)\n",
    "    norm_s = norm_s.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    return norm_s\n",
    "\n",
    "# Cell 7: Apply comparisons (Vectorized) and calculate match scores\n",
    "print(\"\\nApplying comparisons (vectorized)...\")\n",
    "\n",
    "# --- 1. Payee Name Comparison ---\n",
    "name1_norm = normalize_name_series(df_merged['payee_name'])\n",
    "name2_norm = normalize_name_series(df_merged['PRES_NAME'])\n",
    "name_comparable = df_merged['payee_name'].notna() & df_merged['PRES_NAME'].notna()\n",
    "df_merged['payee_name_match_status'] = name_comparable & (name1_norm == name2_norm)\n",
    "\n",
    "# For payee_name_match_details (using apply for rich string, this is the slowest part but acceptable for one col)\n",
    "def generate_name_details(row, norm_s1_col, norm_s2_col):\n",
    "    idx = row.name # get the original index\n",
    "    is_comparable = row['name_comparable_temp'] # Use temporary column passed via closure/context\n",
    "    \n",
    "    if not is_comparable:\n",
    "        return \"One or both names are NaN\"\n",
    "    \n",
    "    n1 = norm_s1_col.loc[idx]\n",
    "    n2 = norm_s2_col.loc[idx]\n",
    "    \n",
    "    if row['payee_name_match_status']:\n",
    "        return f\"Normalized Match: Ext: '{n1}', Gold: '{n2}'\"\n",
    "    else:\n",
    "        return f\"Normalized No Match: Ext: '{n1}', Gold: '{n2}'\"\n",
    "\n",
    "df_merged['name_comparable_temp'] = name_comparable # Create temporary column for apply access\n",
    "print(\"Generating payee name match details (this may take a moment for 30k rows)...\")\n",
    "if TQDM_AVAILABLE:\n",
    "    df_merged['payee_name_match_details'] = df_merged.progress_apply(\n",
    "        lambda row: generate_name_details(row, name1_norm, name2_norm), axis=1\n",
    "    )\n",
    "else:\n",
    "    df_merged['payee_name_match_details'] = df_merged.apply(\n",
    "        lambda row: generate_name_details(row, name1_norm, name2_norm), axis=1\n",
    "    )\n",
    "del df_merged['name_comparable_temp'] # cleanup\n",
    "\n",
    "# --- 2. Amount Comparison ---\n",
    "amount1_num = pd.to_numeric(df_merged['amount_numeric'], errors='coerce')\n",
    "amount2_num = pd.to_numeric(df_merged['CAR_AMOUNT'], errors='coerce')\n",
    "amount_comparable = amount1_num.notna() & amount2_num.notna()\n",
    "# Compare as floats for precision (e.g., 750 == 750.0)\n",
    "df_merged['amount_match_status'] = amount_comparable & (amount1_num.astype(float) == amount2_num.astype(float))\n",
    "\n",
    "# --- 3. MICR Code Comparison ---\n",
    "micr1_norm = df_merged['micr_code'].astype(str).str.strip()\n",
    "micr2_norm = df_merged['micr_code_gold'].astype(str).str.strip() # Already constructed\n",
    "micr_comparable = df_merged['micr_code'].notna() & df_merged['micr_code_gold'].notna() # Gold MICR can be empty if all parts NaN\n",
    "df_merged['micr_match_status'] = micr_comparable & (micr1_norm == micr2_norm)\n",
    "\n",
    "# --- 4. Calculate Fields Matched and Fields to Compare ---\n",
    "df_merged['fields_to_compare'] = name_comparable.astype(int) + \\\n",
    "                                 amount_comparable.astype(int) + \\\n",
    "                                 micr_comparable.astype(int)\n",
    "\n",
    "df_merged['fields_matched'] = df_merged['payee_name_match_status'].astype(int) + \\\n",
    "                              df_merged['amount_match_status'].astype(int) + \\\n",
    "                              df_merged['micr_match_status'].astype(int)\n",
    "\n",
    "# --- 5. Calculate Match Percentage ---\n",
    "df_merged['match_percentage'] = np.where(\n",
    "    df_merged['fields_to_compare'] > 0,\n",
    "    (df_merged['fields_matched'] / df_merged['fields_to_compare']) * 100,\n",
    "    0  # Set to 0 if fields_to_compare is 0\n",
    ").round(2) # Round to 2 decimal places\n",
    "\n",
    "print(\"\\nDataFrame with Match Status and Percentage (first 5 rows):\")\n",
    "print(df_merged[['INSTRUMENT_ID_EXTRACT', 'payee_name_match_status', 'amount_match_status', 'micr_match_status',\n",
    "                 'fields_matched', 'fields_to_compare', 'match_percentage', 'payee_name_match_details']].head())\n",
    "\n",
    "# Cell 8: Select relevant columns for the output and save to Excel\n",
    "print(\"\\nPreparing output file...\")\n",
    "output_columns = [\n",
    "    'filepath', 'INSTRUMENT_ID_EXTRACT', 'payee_name', 'amount_numeric', 'micr_code', \n",
    "    'INSTRUMENT_ID', 'PRES_NAME', 'CAR_AMOUNT', 'micr_code_gold', \n",
    "    'SCAN_INSTRUMENT_NUMBER', 'SCAN_PAYEE_BANK_CITY_CODE', 'SCAN_PAYEE_BANK_CODE', \n",
    "    'SCAN_PAYEE_BANK_BRANCH_CODE', 'SCAN_MICR_ACNO', 'SCAN_INSTRUMENT_TYPE', \n",
    "    'payee_name_match_status', 'payee_name_match_details', 'amount_match_status', 'micr_match_status', \n",
    "    'fields_matched', 'fields_to_compare', 'match_percentage' \n",
    "]\n",
    "\n",
    "final_output_columns = [col for col in output_columns if col in df_merged.columns]\n",
    "df_output = df_merged[final_output_columns]\n",
    "\n",
    "try:\n",
    "    output_file_name = 'comparison_results_vectorized.xlsx'\n",
    "    df_output.to_excel(output_file_name, index=False)\n",
    "    print(f\"\\nComparison results saved to '{output_file_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to Excel: {e}\")\n",
    "\n",
    "# Cell 9: Display overall statistics (optional)\n",
    "print(\"\\nCalculating overall statistics...\")\n",
    "total_records = len(df_merged)\n",
    "perfect_matches_df = df_merged[df_merged['fields_to_compare'] > 0]\n",
    "perfect_matches = len(perfect_matches_df[perfect_matches_df['match_percentage'] == 100])\n",
    "\n",
    "overall_field_matches_sum = df_merged['fields_matched'].sum()\n",
    "overall_fields_to_compare_sum = df_merged['fields_to_compare'].sum()\n",
    "\n",
    "overall_match_accuracy = (overall_field_matches_sum / overall_fields_to_compare_sum * 100) if overall_fields_to_compare_sum > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Overall Statistics ---\")\n",
    "print(f\"Total Records Processed: {total_records}\")\n",
    "print(f\"Records with 100% Match (among comparable): {perfect_matches}\")\n",
    "\n",
    "if overall_fields_to_compare_sum > 0:\n",
    "    print(f\"Overall Field Match Accuracy: {overall_match_accuracy:.2f}% ({overall_field_matches_sum}/{overall_fields_to_compare_sum} fields)\")\n",
    "else:\n",
    "    print(\"Overall Field Match Accuracy: Not applicable (no fields to compare or all comparable fields were NaN)\")\n",
    "\n",
    "if 'payee_name_match_status' in df_merged.columns:\n",
    "    name_matches = df_merged['payee_name_match_status'].sum() # Sum of True booleans\n",
    "    # name_total_comparable is the sum of the 'name_comparable' boolean Series\n",
    "    name_total_comparable_count = name_comparable.sum()\n",
    "    name_accuracy = (name_matches / name_total_comparable_count * 100) if name_total_comparable_count > 0 else 0\n",
    "    print(f\"Payee Name Match Accuracy: {name_accuracy:.2f}% ({name_matches}/{name_total_comparable_count} comparable pairs)\")\n",
    "\n",
    "if 'amount_match_status' in df_merged.columns:\n",
    "    amount_matches = df_merged['amount_match_status'].sum()\n",
    "    amount_total_comparable_count = amount_comparable.sum()\n",
    "    amount_accuracy = (amount_matches / amount_total_comparable_count * 100) if amount_total_comparable_count > 0 else 0\n",
    "    print(f\"Amount Match Accuracy: {amount_accuracy:.2f}% ({amount_matches}/{amount_total_comparable_count} comparable pairs)\")\n",
    "\n",
    "if 'micr_match_status' in df_merged.columns:\n",
    "    micr_matches = df_merged['micr_match_status'].sum()\n",
    "    micr_total_comparable_count = micr_comparable.sum() # micr_comparable was the boolean Series for this\n",
    "    micr_accuracy = (micr_matches / micr_total_comparable_count * 100) if micr_total_comparable_count > 0 else 0\n",
    "    print(f\"MICR Code Match Accuracy: {micr_accuracy:.2f}% ({micr_matches}/{micr_total_comparable_count} comparable pairs)\")\n",
    "\n",
    "print(\"--- End of Optimized Notebook ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
