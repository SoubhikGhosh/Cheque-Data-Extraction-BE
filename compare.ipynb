{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np # Import numpy\n",
    "try:\n",
    "    from tqdm.auto import tqdm  # For progress bars\n",
    "    TQDM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TQDM_AVAILABLE = False\n",
    "    print(\"Warning: tqdm library not found. Progress bars will not be shown. To enable them, please install tqdm: pip install tqdm\")\n",
    "    # Define a dummy tqdm if not available so the code doesn't break\n",
    "    def tqdm(iterable, *args, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "\n",
    "# Cell 2: Load the Excel files\n",
    "# Replace 'extract.xlsx' and 'gold.xlsx' with the actual file paths\n",
    "try:\n",
    "    df_extract = pd.read_excel('extract.xlsx')\n",
    "    df_gold = pd.read_excel('gold.xlsx')\n",
    "    print(\"Successfully loaded 'extract.xlsx' and 'gold.xlsx'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"One or both Excel files not found. Using dummy data for demonstration.\")\n",
    "    # Create dummy dataframes for demonstration if files are not found\n",
    "    data_extract = {\n",
    "        'filepath': ['/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/2510600056001201252_f.jpeg',\n",
    "                     '/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/1234567890123456789_f.jpeg',\n",
    "                     '/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/9999999999999999999_f.jpeg',\n",
    "                     '/tmp/job_e6b7dd30-4f60-4f8b-8331-2458fea95c06_eh6vxyz3/zip_0_new/GenAI-OUT-F-IMG-16042025-30000/0000000000000000000_f.jpeg'], # Added a no-match record\n",
    "        'payee_name': ['John Doe!', 'Jane Smith.', 'Another Person', 'No Match Name'],\n",
    "        'amount_numeric': [750, 1200.50, 500, 100],\n",
    "        'micr_code': ['123456CITYBANKBRANCH001SAVINGS', '987654CITY2BANK2BRANCH2002CURRENT', '111222CITY3BANK3BRANCH3003SAVINGS', 'NOMATCHMICR']\n",
    "    }\n",
    "    df_extract = pd.DataFrame(data_extract)\n",
    "\n",
    "    data_gold = {\n",
    "        'TRANSACTION_DATE': ['16/04/2025', '17/04/2025', '18/04/2025'],\n",
    "        'INSTRUMENT_ID': [2510600056001201252, 9876543210987654321, 9999999999999999999],\n",
    "        'FLOW_TYPE': ['INWARD', 'OUTWARD', 'INWARD'],\n",
    "        'SCAN_INSTRUMENT_NUMBER': [123456, 987654, 111222],\n",
    "        'SCAN_PAYEE_BANK_CITY_CODE': ['CITY', 'CITY2', 'CITY3'],\n",
    "        'SCAN_PAYEE_BANK_CODE': ['BANK', 'BANK2', 'BANK3'],\n",
    "        'SCAN_PAYEE_BANK_BRANCH_CODE': ['BRANCH', 'BRANCH2', 'BRANCH3'],\n",
    "        'SCAN_MICR_ACNO': [1, 0, 3],\n",
    "        'SCAN_INSTRUMENT_TYPE': ['SAVINGS', 'CURRENT', 'SAVINGS'],\n",
    "        'PRES_NAME': [' John Doe ', 'Jane  Smith', 'Another Person '],\n",
    "        'CAR_AMOUNT': [750.00, 1250.00, 500.00]\n",
    "    }\n",
    "    df_gold = pd.DataFrame(data_gold)\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "print(\"\\nExcel 1 (Extract) Head:\")\n",
    "print(df_extract.head())\n",
    "print(\"\\nExcel 2 (Gold) Head:\")\n",
    "print(df_gold.head())\n",
    "\n",
    "# Cell 3: Preprocess df_extract\n",
    "# Extract INSTRUMENT_ID from filepath\n",
    "def extract_instrument_id(filepath):\n",
    "    if pd.isna(filepath):\n",
    "        return None\n",
    "    match = re.search(r'/([^/]+)_f\\.jpeg$', str(filepath))\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = df_extract['filepath'].apply(extract_instrument_id)\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = pd.to_numeric(df_extract['INSTRUMENT_ID_EXTRACT'], errors='coerce')\n",
    "\n",
    "print(\"\\nDF Extract after INSTRUMENT_ID extraction:\")\n",
    "print(df_extract.head())\n",
    "\n",
    "# Cell 4: Preprocess df_gold\n",
    "# Construct micr_code in df_gold\n",
    "def construct_micr(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['SCAN_INSTRUMENT_NUMBER']):\n",
    "        parts.append(str(row['SCAN_INSTRUMENT_NUMBER']))\n",
    "    if pd.notna(row['SCAN_PAYEE_BANK_CITY_CODE']):\n",
    "        parts.append(str(row['SCAN_PAYEE_BANK_CITY_CODE']))\n",
    "    if pd.notna(row['SCAN_PAYEE_BANK_CODE']):\n",
    "        parts.append(str(row['SCAN_PAYEE_BANK_CODE']))\n",
    "    if pd.notna(row['SCAN_PAYEE_BANK_BRANCH_CODE']):\n",
    "        parts.append(str(row['SCAN_PAYEE_BANK_BRANCH_CODE']))\n",
    "    if pd.notna(row['SCAN_MICR_ACNO']) and row['SCAN_MICR_ACNO'] != 0:\n",
    "        parts.append(str(int(row['SCAN_MICR_ACNO'])))\n",
    "    if pd.notna(row['SCAN_INSTRUMENT_TYPE']):\n",
    "        parts.append(str(row['SCAN_INSTRUMENT_TYPE']))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "df_gold['micr_code_gold'] = df_gold.apply(construct_micr, axis=1)\n",
    "df_gold['INSTRUMENT_ID'] = pd.to_numeric(df_gold['INSTRUMENT_ID'], errors='coerce')\n",
    "\n",
    "print(\"\\nDF Gold after micr_code_gold construction:\")\n",
    "print(df_gold.head())\n",
    "\n",
    "# Cell 5: Merge the DataFrames\n",
    "df_merged = pd.merge(df_extract, df_gold, left_on='INSTRUMENT_ID_EXTRACT', right_on='INSTRUMENT_ID', how='left', suffixes=('_extract', '_gold'))\n",
    "\n",
    "print(\"\\nMerged DataFrame Head:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# Cell 6: Define comparison functions\n",
    "def compare_names(name1, name2):\n",
    "    if pd.isna(name1) or pd.isna(name2):\n",
    "        return False, \"One or both names are NaN\"\n",
    "    norm_name1 = str(name1).strip().lower()\n",
    "    norm_name2 = str(name2).strip().lower()\n",
    "    norm_name1 = re.sub(r'[^a-z0-9\\s]', '', norm_name1)\n",
    "    norm_name2 = re.sub(r'[^a-z0-9\\s]', '', norm_name2)\n",
    "    norm_name1 = re.sub(r'\\s+', ' ', norm_name1).strip()\n",
    "    norm_name2 = re.sub(r'\\s+', ' ', norm_name2).strip()\n",
    "    return norm_name1 == norm_name2, f\"Normalized Extract: '{norm_name1}', Normalized Gold: '{norm_name2}'\"\n",
    "\n",
    "def compare_amounts(amount1, amount2):\n",
    "    if pd.isna(amount1) or pd.isna(amount2):\n",
    "        return False\n",
    "    try:\n",
    "        return float(amount1) == float(amount2)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def compare_micr(micr1, micr2):\n",
    "    if pd.isna(micr1) or pd.isna(micr2):\n",
    "        return False\n",
    "    return str(micr1).strip() == str(micr2).strip()\n",
    "\n",
    "# Cell 7: Apply comparison functions and calculate match scores\n",
    "if TQDM_AVAILABLE:\n",
    "    tqdm.pandas(desc=\"Processing records for comparison\") \n",
    "\n",
    "df_merged['payee_name_match_status'] = False\n",
    "df_merged['payee_name_match_details'] = ''\n",
    "df_merged['amount_match_status'] = False\n",
    "df_merged['micr_match_status'] = False\n",
    "df_merged['fields_matched'] = 0\n",
    "\n",
    "print(\"\\nApplying comparisons:\")\n",
    "# Use tqdm directly on iterrows\n",
    "for index, row in tqdm(df_merged.iterrows(), total=df_merged.shape[0], desc=\"Comparing records\"):\n",
    "    current_matches = 0\n",
    "    # Compare Payee Name\n",
    "    if 'payee_name' in df_merged.columns and 'PRES_NAME' in df_merged.columns:\n",
    "        if pd.notna(row['payee_name']) and pd.notna(row['PRES_NAME']):\n",
    "            name_match_result, name_match_detail_str = compare_names(row['payee_name'], row['PRES_NAME'])\n",
    "            df_merged.loc[index, 'payee_name_match_status'] = name_match_result\n",
    "            df_merged.loc[index, 'payee_name_match_details'] = name_match_detail_str\n",
    "            if name_match_result:\n",
    "                current_matches += 1\n",
    "        else:\n",
    "             df_merged.loc[index, 'payee_name_match_details'] = \"One or both names missing for comparison\"\n",
    "    else:\n",
    "        df_merged.loc[index, 'payee_name_match_details'] = \"Payee name columns not found\"\n",
    "\n",
    "    # Compare Amount\n",
    "    if 'amount_numeric' in df_merged.columns and 'CAR_AMOUNT' in df_merged.columns:\n",
    "        if pd.notna(row['amount_numeric']) and pd.notna(row['CAR_AMOUNT']):\n",
    "            amount_match_result = compare_amounts(row['amount_numeric'], row['CAR_AMOUNT'])\n",
    "            df_merged.loc[index, 'amount_match_status'] = amount_match_result\n",
    "            if amount_match_result:\n",
    "                current_matches += 1\n",
    "    \n",
    "    # Compare MICR\n",
    "    if 'micr_code' in df_merged.columns and 'micr_code_gold' in df_merged.columns:\n",
    "        if pd.notna(row['micr_code']) and pd.notna(row['micr_code_gold']):\n",
    "            micr_match_result = compare_micr(row['micr_code'], row['micr_code_gold'])\n",
    "            df_merged.loc[index, 'micr_match_status'] = micr_match_result\n",
    "            if micr_match_result:\n",
    "                current_matches += 1\n",
    "    df_merged.loc[index, 'fields_matched'] = current_matches\n",
    "\n",
    "fields_to_compare_list = []\n",
    "for index, row in df_merged.iterrows():\n",
    "    count = 0\n",
    "    if 'payee_name' in df_merged.columns and 'PRES_NAME' in df_merged.columns and \\\n",
    "       pd.notna(row['payee_name']) and pd.notna(row['PRES_NAME']):\n",
    "        count += 1\n",
    "    if 'amount_numeric' in df_merged.columns and 'CAR_AMOUNT' in df_merged.columns and \\\n",
    "       pd.notna(row['amount_numeric']) and pd.notna(row['CAR_AMOUNT']):\n",
    "        count += 1\n",
    "    if 'micr_code' in df_merged.columns and 'micr_code_gold' in df_merged.columns and \\\n",
    "       pd.notna(row['micr_code']) and pd.notna(row['micr_code_gold']):\n",
    "        count += 1\n",
    "    fields_to_compare_list.append(count)\n",
    "df_merged['fields_to_compare'] = fields_to_compare_list\n",
    "\n",
    "# Calculate match percentage using np.where to avoid division by zero issues and recursion\n",
    "df_merged['match_percentage'] = np.where(\n",
    "    df_merged['fields_to_compare'] > 0,\n",
    "    (df_merged['fields_matched'] / df_merged['fields_to_compare']) * 100,\n",
    "    0  # Set to 0 if fields_to_compare is 0\n",
    ")\n",
    "df_merged['match_percentage'] = df_merged['match_percentage'].fillna(0) # Ensure any other NaNs become 0\n",
    "\n",
    "\n",
    "print(\"\\nDataFrame with Match Status and Percentage:\")\n",
    "print(df_merged[['INSTRUMENT_ID_EXTRACT', 'payee_name_match_status', 'amount_match_status', 'micr_match_status',\n",
    "                 'fields_matched', 'fields_to_compare', 'match_percentage']].head())\n",
    "\n",
    "# Cell 8: Select relevant columns for the output and save to Excel\n",
    "output_columns = [\n",
    "    'filepath', 'INSTRUMENT_ID_EXTRACT', 'payee_name', 'amount_numeric', 'micr_code', \n",
    "    'INSTRUMENT_ID', 'PRES_NAME', 'CAR_AMOUNT', 'micr_code_gold', \n",
    "    'SCAN_INSTRUMENT_NUMBER', 'SCAN_PAYEE_BANK_CITY_CODE', 'SCAN_PAYEE_BANK_CODE', \n",
    "    'SCAN_PAYEE_BANK_BRANCH_CODE', 'SCAN_MICR_ACNO', 'SCAN_INSTRUMENT_TYPE', \n",
    "    'payee_name_match_status', 'payee_name_match_details', 'amount_match_status', 'micr_match_status', \n",
    "    'fields_matched', 'fields_to_compare', 'match_percentage' \n",
    "]\n",
    "\n",
    "final_output_columns = [col for col in output_columns if col in df_merged.columns]\n",
    "df_output = df_merged[final_output_columns]\n",
    "\n",
    "try:\n",
    "    output_file_name = 'comparison_results_final.xlsx'\n",
    "    df_output.to_excel(output_file_name, index=False)\n",
    "    print(f\"\\nComparison results saved to '{output_file_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to Excel: {e}\")\n",
    "\n",
    "# Cell 9: Display overall statistics (optional)\n",
    "total_records = len(df_merged)\n",
    "# For perfect matches, consider only rows where there was something to compare\n",
    "perfect_matches_df = df_merged[df_merged['fields_to_compare'] > 0]\n",
    "perfect_matches = len(perfect_matches_df[perfect_matches_df['match_percentage'] == 100])\n",
    "\n",
    "overall_field_matches_sum = df_merged['fields_matched'].sum()\n",
    "overall_fields_to_compare_sum = df_merged['fields_to_compare'].sum()\n",
    "\n",
    "overall_match_accuracy = (overall_field_matches_sum / overall_fields_to_compare_sum * 100) if overall_fields_to_compare_sum > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Overall Statistics ---\")\n",
    "print(f\"Total Records Processed: {total_records}\")\n",
    "print(f\"Records with 100% Match (among comparable): {perfect_matches}\")\n",
    "\n",
    "if overall_fields_to_compare_sum > 0:\n",
    "    print(f\"Overall Field Match Accuracy: {overall_match_accuracy:.2f}% ({overall_field_matches_sum}/{overall_fields_to_compare_sum} fields)\")\n",
    "else:\n",
    "    print(\"Overall Field Match Accuracy: Not applicable (no fields to compare or all comparable fields were NaN)\")\n",
    "\n",
    "if 'payee_name_match_status' in df_merged.columns:\n",
    "    name_matches = df_merged['payee_name_match_status'].sum()\n",
    "    name_total_comparable = len(df_merged[df_merged['payee_name'].notna() & df_merged['PRES_NAME'].notna()])\n",
    "    name_accuracy = (name_matches / name_total_comparable * 100) if name_total_comparable > 0 else 0\n",
    "    print(f\"Payee Name Match Accuracy: {name_accuracy:.2f}% ({name_matches}/{name_total_comparable} comparable pairs)\")\n",
    "\n",
    "if 'amount_match_status' in df_merged.columns:\n",
    "    amount_matches = df_merged['amount_match_status'].sum()\n",
    "    amount_total_comparable = len(df_merged[df_merged['amount_numeric'].notna() & df_merged['CAR_AMOUNT'].notna()])\n",
    "    amount_accuracy = (amount_matches / amount_total_comparable * 100) if amount_total_comparable > 0 else 0\n",
    "    print(f\"Amount Match Accuracy: {amount_accuracy:.2f}% ({amount_matches}/{amount_total_comparable} comparable pairs)\")\n",
    "\n",
    "if 'micr_match_status' in df_merged.columns:\n",
    "    micr_matches = df_merged['micr_match_status'].sum()\n",
    "    micr_total_comparable = len(df_merged[df_merged['micr_code'].notna() & df_merged['micr_code_gold'].notna()])\n",
    "    micr_accuracy = (micr_matches / micr_total_comparable * 100) if micr_total_comparable > 0 else 0\n",
    "    print(f\"MICR Code Match Accuracy: {micr_accuracy:.2f}% ({micr_matches}/{micr_total_comparable} comparable pairs)\")\n",
    "\n",
    "print(\"--- End of Notebook ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd734dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np # Import numpy\n",
    "try:\n",
    "    from tqdm.auto import tqdm  # For progress bars\n",
    "    tqdm.pandas() # Initialize tqdm for pandas functions like progress_apply\n",
    "    TQDM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TQDM_AVAILABLE = False\n",
    "    print(\"Warning: tqdm library not found. Progress bars for apply functions will not be shown. To enable them, please install tqdm: pip install tqdm\")\n",
    "    # Define a dummy tqdm if not available so the code doesn't break\n",
    "    def tqdm(iterable, *args, **kwargs): # This dummy is for iterables\n",
    "        return iterable\n",
    "    # If tqdm.pandas() can't be called, progress_apply will just be apply\n",
    "    # We can create a dummy progress_apply if needed, or let it default to apply\n",
    "    # For simplicity, if tqdm is not there, progress_apply will become a direct apply call later\n",
    "\n",
    "# Cell 2: Load the Excel files\n",
    "# Replace 'extract.xlsx' and 'gold.xlsx' with the actual file paths\n",
    "try:\n",
    "    df_extract = pd.read_excel('extract.xlsx')\n",
    "    df_gold = pd.read_excel('gold.xlsx')\n",
    "    print(\"Successfully loaded 'extract.xlsx' and 'gold.xlsx'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"One or both Excel files not found. Using dummy data for demonstration (30k rows).\")\n",
    "    # Create larger dummy dataframes for demonstration\n",
    "    num_records = 30000\n",
    "    base_instrument_id = 2510600056001201252\n",
    "    data_extract = {\n",
    "        'filepath': [f'/tmp/job/path/to/{base_instrument_id + i}_f.jpeg' for i in range(num_records)],\n",
    "        'payee_name': [f'Payee Name {i % 100}!' if i % 2 == 0 else f' Payee Name {i % 100} ' for i in range(num_records)],\n",
    "        'amount_numeric': [750 + (i%1000) if i % 2 == 0 else (750 + (i%1000)) * 1.0 for i in range(num_records)],\n",
    "        'micr_code': [f'123456CITYBANKBRANCH00{i%10}SAVINGS' if i%3==0 else f'654321CITYBANKALT0{i%5}CURRENT' for i in range(num_records)]\n",
    "    }\n",
    "    df_extract = pd.DataFrame(data_extract)\n",
    "    # Add some NaNs for testing robustness\n",
    "    for col in ['payee_name', 'amount_numeric', 'micr_code']:\n",
    "      df_extract.loc[df_extract.sample(frac=0.05).index, col] = np.nan\n",
    "\n",
    "\n",
    "    data_gold = {\n",
    "        'TRANSACTION_DATE': [f'{(i%28)+1}/{(i%12)+1}/2025' for i in range(num_records)],\n",
    "        'INSTRUMENT_ID': [base_instrument_id + i for i in range(num_records)],\n",
    "        'FLOW_TYPE': ['INWARD' if i % 2 == 0 else 'OUTWARD' for i in range(num_records)],\n",
    "        'SCAN_INSTRUMENT_NUMBER': [123456 + i for i in range(num_records)],\n",
    "        'SCAN_PAYEE_BANK_CITY_CODE': ['CITY' if i%2==0 else 'CITYALT' for i in range(num_records)],\n",
    "        'SCAN_PAYEE_BANK_CODE': ['BANK' for i in range(num_records)],\n",
    "        'SCAN_PAYEE_BANK_BRANCH_CODE': ['BRANCH' if i%2==0 else 'BRANCHALT' for i in range(num_records)],\n",
    "        'SCAN_MICR_ACNO': [i % 5 if (i % 5 != 0) else (0 if i%10==0 else np.nan) for i in range(num_records)], # include 0 and NaN\n",
    "        'SCAN_INSTRUMENT_TYPE': ['SAVINGS' if i%3==0 else 'CURRENT' for i in range(num_records)],\n",
    "        'PRES_NAME': [f'Payee Name {i % 100}' for i in range(num_records)], # Gold standard names\n",
    "        'CAR_AMOUNT': [750 + (i%1000) for i in range(num_records)]\n",
    "    }\n",
    "    df_gold = pd.DataFrame(data_gold)\n",
    "    # Add some NaNs for testing robustness\n",
    "    for col in ['PRES_NAME', 'CAR_AMOUNT', 'SCAN_MICR_ACNO']:\n",
    "      df_gold.loc[df_gold.sample(frac=0.05).index, col] = np.nan\n",
    "\n",
    "\n",
    "print(f\"\\nExcel 1 (Extract) Head ({len(df_extract)} rows):\")\n",
    "print(df_extract.head())\n",
    "print(f\"\\nExcel 2 (Gold) Head ({len(df_gold)} rows):\")\n",
    "print(df_gold.head())\n",
    "\n",
    "# Cell 3: Preprocess df_extract (Vectorized where possible)\n",
    "print(\"\\nPreprocessing df_extract...\")\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = df_extract['filepath'].astype(str).str.extract(r'/([^/]+)_f\\.jpeg$')[0]\n",
    "df_extract['INSTRUMENT_ID_EXTRACT'] = pd.to_numeric(df_extract['INSTRUMENT_ID_EXTRACT'], errors='coerce')\n",
    "print(\"DF Extract after INSTRUMENT_ID extraction head:\")\n",
    "print(df_extract.head())\n",
    "\n",
    "# Cell 4: Preprocess df_gold (Vectorized MICR construction)\n",
    "print(\"\\nPreprocessing df_gold (vectorized MICR)...\")\n",
    "\n",
    "# Convert components to string, filling NaNs with empty strings\n",
    "s_instr_num = df_gold['SCAN_INSTRUMENT_NUMBER'].fillna('').astype(str)\n",
    "s_city = df_gold['SCAN_PAYEE_BANK_CITY_CODE'].fillna('').astype(str)\n",
    "s_bank = df_gold['SCAN_PAYEE_BANK_CODE'].fillna('').astype(str)\n",
    "s_branch = df_gold['SCAN_PAYEE_BANK_BRANCH_CODE'].fillna('').astype(str)\n",
    "s_instr_type = df_gold['SCAN_INSTRUMENT_TYPE'].fillna('').astype(str)\n",
    "\n",
    "# Conditional SCAN_MICR_ACNO\n",
    "# Ensure it's numeric before comparison, then convert to int string, or empty\n",
    "micr_acno_num = pd.to_numeric(df_gold['SCAN_MICR_ACNO'], errors='coerce')\n",
    "s_micr_acno = np.where(\n",
    "    (micr_acno_num.notna()) & (micr_acno_num != 0),\n",
    "    micr_acno_num.astype(float).astype(int).astype(str), # astype(float) handles cases like \"1.0\" before int\n",
    "    ''\n",
    ")\n",
    "df_gold['micr_code_gold'] = s_instr_num + s_city + s_bank + s_branch + s_micr_acno + s_instr_type\n",
    "df_gold['INSTRUMENT_ID'] = pd.to_numeric(df_gold['INSTRUMENT_ID'], errors='coerce')\n",
    "print(\"DF Gold after micr_code_gold construction head:\")\n",
    "print(df_gold[['INSTRUMENT_ID', 'micr_code_gold']].head())\n",
    "\n",
    "# Cell 5: Merge the DataFrames\n",
    "print(\"\\nMerging DataFrames...\")\n",
    "df_merged = pd.merge(df_extract, df_gold, left_on='INSTRUMENT_ID_EXTRACT', right_on='INSTRUMENT_ID', how='left', suffixes=('_extract', '_gold'))\n",
    "print(f\"Merged DataFrame shape: {df_merged.shape}\")\n",
    "print(\"Merged DataFrame Head:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# Cell 6: Comparison logic (will be applied vectorially in Cell 7)\n",
    "# Normalization function for names (can be applied to series)\n",
    "def normalize_name_series(name_series):\n",
    "    if not isinstance(name_series, pd.Series):\n",
    "        name_series = pd.Series(name_series)\n",
    "    norm_s = name_series.astype(str).str.strip().str.lower()\n",
    "    norm_s = norm_s.str.replace(r'[^a-z0-9\\s]', '', regex=True)\n",
    "    norm_s = norm_s.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    return norm_s\n",
    "\n",
    "# Cell 7: Apply comparisons (Vectorized) and calculate match scores\n",
    "print(\"\\nApplying comparisons (vectorized)...\")\n",
    "\n",
    "# --- 1. Payee Name Comparison ---\n",
    "name1_norm = normalize_name_series(df_merged['payee_name'])\n",
    "name2_norm = normalize_name_series(df_merged['PRES_NAME'])\n",
    "name_comparable = df_merged['payee_name'].notna() & df_merged['PRES_NAME'].notna()\n",
    "df_merged['payee_name_match_status'] = name_comparable & (name1_norm == name2_norm)\n",
    "\n",
    "# For payee_name_match_details (using apply for rich string, this is the slowest part but acceptable for one col)\n",
    "def generate_name_details(row, norm_s1_col, norm_s2_col):\n",
    "    idx = row.name # get the original index\n",
    "    is_comparable = row['name_comparable_temp'] # Use temporary column passed via closure/context\n",
    "    \n",
    "    if not is_comparable:\n",
    "        return \"One or both names are NaN\"\n",
    "    \n",
    "    n1 = norm_s1_col.loc[idx]\n",
    "    n2 = norm_s2_col.loc[idx]\n",
    "    \n",
    "    if row['payee_name_match_status']:\n",
    "        return f\"Normalized Match: Ext: '{n1}', Gold: '{n2}'\"\n",
    "    else:\n",
    "        return f\"Normalized No Match: Ext: '{n1}', Gold: '{n2}'\"\n",
    "\n",
    "df_merged['name_comparable_temp'] = name_comparable # Create temporary column for apply access\n",
    "print(\"Generating payee name match details (this may take a moment for 30k rows)...\")\n",
    "if TQDM_AVAILABLE:\n",
    "    df_merged['payee_name_match_details'] = df_merged.progress_apply(\n",
    "        lambda row: generate_name_details(row, name1_norm, name2_norm), axis=1\n",
    "    )\n",
    "else:\n",
    "    df_merged['payee_name_match_details'] = df_merged.apply(\n",
    "        lambda row: generate_name_details(row, name1_norm, name2_norm), axis=1\n",
    "    )\n",
    "del df_merged['name_comparable_temp'] # cleanup\n",
    "\n",
    "# --- 2. Amount Comparison ---\n",
    "amount1_num = pd.to_numeric(df_merged['amount_numeric'], errors='coerce')\n",
    "amount2_num = pd.to_numeric(df_merged['CAR_AMOUNT'], errors='coerce')\n",
    "amount_comparable = amount1_num.notna() & amount2_num.notna()\n",
    "# Compare as floats for precision (e.g., 750 == 750.0)\n",
    "df_merged['amount_match_status'] = amount_comparable & (amount1_num.astype(float) == amount2_num.astype(float))\n",
    "\n",
    "# --- 3. MICR Code Comparison ---\n",
    "micr1_norm = df_merged['micr_code'].astype(str).str.strip()\n",
    "micr2_norm = df_merged['micr_code_gold'].astype(str).str.strip() # Already constructed\n",
    "micr_comparable = df_merged['micr_code'].notna() & df_merged['micr_code_gold'].notna() # Gold MICR can be empty if all parts NaN\n",
    "df_merged['micr_match_status'] = micr_comparable & (micr1_norm == micr2_norm)\n",
    "\n",
    "# --- 4. Calculate Fields Matched and Fields to Compare ---\n",
    "df_merged['fields_to_compare'] = name_comparable.astype(int) + \\\n",
    "                                 amount_comparable.astype(int) + \\\n",
    "                                 micr_comparable.astype(int)\n",
    "\n",
    "df_merged['fields_matched'] = df_merged['payee_name_match_status'].astype(int) + \\\n",
    "                              df_merged['amount_match_status'].astype(int) + \\\n",
    "                              df_merged['micr_match_status'].astype(int)\n",
    "\n",
    "# --- 5. Calculate Match Percentage ---\n",
    "df_merged['match_percentage'] = np.where(\n",
    "    df_merged['fields_to_compare'] > 0,\n",
    "    (df_merged['fields_matched'] / df_merged['fields_to_compare']) * 100,\n",
    "    0  # Set to 0 if fields_to_compare is 0\n",
    ").round(2) # Round to 2 decimal places\n",
    "\n",
    "print(\"\\nDataFrame with Match Status and Percentage (first 5 rows):\")\n",
    "print(df_merged[['INSTRUMENT_ID_EXTRACT', 'payee_name_match_status', 'amount_match_status', 'micr_match_status',\n",
    "                 'fields_matched', 'fields_to_compare', 'match_percentage', 'payee_name_match_details']].head())\n",
    "\n",
    "# Cell 8: Select relevant columns for the output and save to Excel\n",
    "print(\"\\nPreparing output file...\")\n",
    "output_columns = [\n",
    "    'filepath', 'INSTRUMENT_ID_EXTRACT', 'payee_name', 'amount_numeric', 'micr_code', \n",
    "    'INSTRUMENT_ID', 'PRES_NAME', 'CAR_AMOUNT', 'micr_code_gold', \n",
    "    'SCAN_INSTRUMENT_NUMBER', 'SCAN_PAYEE_BANK_CITY_CODE', 'SCAN_PAYEE_BANK_CODE', \n",
    "    'SCAN_PAYEE_BANK_BRANCH_CODE', 'SCAN_MICR_ACNO', 'SCAN_INSTRUMENT_TYPE', \n",
    "    'payee_name_match_status', 'payee_name_match_details', 'amount_match_status', 'micr_match_status', \n",
    "    'fields_matched', 'fields_to_compare', 'match_percentage' \n",
    "]\n",
    "\n",
    "final_output_columns = [col for col in output_columns if col in df_merged.columns]\n",
    "df_output = df_merged[final_output_columns]\n",
    "\n",
    "try:\n",
    "    output_file_name = 'comparison_results_vectorized.xlsx'\n",
    "    df_output.to_excel(output_file_name, index=False)\n",
    "    print(f\"\\nComparison results saved to '{output_file_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to Excel: {e}\")\n",
    "\n",
    "# Cell 9: Display overall statistics (optional)\n",
    "print(\"\\nCalculating overall statistics...\")\n",
    "total_records = len(df_merged)\n",
    "perfect_matches_df = df_merged[df_merged['fields_to_compare'] > 0]\n",
    "perfect_matches = len(perfect_matches_df[perfect_matches_df['match_percentage'] == 100])\n",
    "\n",
    "overall_field_matches_sum = df_merged['fields_matched'].sum()\n",
    "overall_fields_to_compare_sum = df_merged['fields_to_compare'].sum()\n",
    "\n",
    "overall_match_accuracy = (overall_field_matches_sum / overall_fields_to_compare_sum * 100) if overall_fields_to_compare_sum > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Overall Statistics ---\")\n",
    "print(f\"Total Records Processed: {total_records}\")\n",
    "print(f\"Records with 100% Match (among comparable): {perfect_matches}\")\n",
    "\n",
    "if overall_fields_to_compare_sum > 0:\n",
    "    print(f\"Overall Field Match Accuracy: {overall_match_accuracy:.2f}% ({overall_field_matches_sum}/{overall_fields_to_compare_sum} fields)\")\n",
    "else:\n",
    "    print(\"Overall Field Match Accuracy: Not applicable (no fields to compare or all comparable fields were NaN)\")\n",
    "\n",
    "if 'payee_name_match_status' in df_merged.columns:\n",
    "    name_matches = df_merged['payee_name_match_status'].sum() # Sum of True booleans\n",
    "    # name_total_comparable is the sum of the 'name_comparable' boolean Series\n",
    "    name_total_comparable_count = name_comparable.sum()\n",
    "    name_accuracy = (name_matches / name_total_comparable_count * 100) if name_total_comparable_count > 0 else 0\n",
    "    print(f\"Payee Name Match Accuracy: {name_accuracy:.2f}% ({name_matches}/{name_total_comparable_count} comparable pairs)\")\n",
    "\n",
    "if 'amount_match_status' in df_merged.columns:\n",
    "    amount_matches = df_merged['amount_match_status'].sum()\n",
    "    amount_total_comparable_count = amount_comparable.sum()\n",
    "    amount_accuracy = (amount_matches / amount_total_comparable_count * 100) if amount_total_comparable_count > 0 else 0\n",
    "    print(f\"Amount Match Accuracy: {amount_accuracy:.2f}% ({amount_matches}/{amount_total_comparable_count} comparable pairs)\")\n",
    "\n",
    "if 'micr_match_status' in df_merged.columns:\n",
    "    micr_matches = df_merged['micr_match_status'].sum()\n",
    "    micr_total_comparable_count = micr_comparable.sum() # micr_comparable was the boolean Series for this\n",
    "    micr_accuracy = (micr_matches / micr_total_comparable_count * 100) if micr_total_comparable_count > 0 else 0\n",
    "    print(f\"MICR Code Match Accuracy: {micr_accuracy:.2f}% ({micr_matches}/{micr_total_comparable_count} comparable pairs)\")\n",
    "\n",
    "print(\"--- End of Optimized Notebook ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel Comparison Analysis\n",
    "# This notebook compares two Excel files cell by cell and calculates match percentages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# 1. Load the Excel files\n",
    "def load_excel_files(extract_file_path, gold_file_path):\n",
    "    \"\"\"\n",
    "    Load both Excel files into pandas DataFrames\n",
    "    \n",
    "    Parameters:\n",
    "    extract_file_path (str): Path to the extract Excel file\n",
    "    gold_file_path (str): Path to the gold Excel file\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (extract_df, gold_df) - Pandas DataFrames containing the data\n",
    "    \"\"\"\n",
    "    print(\"Loading Excel files...\")\n",
    "    extract_df = pd.read_excel(extract_file_path)\n",
    "    gold_df = pd.read_excel(gold_file_path)\n",
    "    \n",
    "    print(f\"Extract Excel shape: {extract_df.shape}\")\n",
    "    print(f\"Gold Excel shape: {gold_df.shape}\")\n",
    "    \n",
    "    return extract_df, gold_df\n",
    "\n",
    "# 2. Process and compare Excel files\n",
    "def process_and_compare(extract_df, gold_df):\n",
    "    \"\"\"\n",
    "    Process and compare the two Excel files.\n",
    "    Note: It's expected that extract_df will have fewer rows than gold_df.\n",
    "    The comparison is done based on records in extract_df, looking for matches in gold_df.\n",
    "    \n",
    "    Parameters:\n",
    "    extract_df (DataFrame): Extract Excel DataFrame (will have fewer rows)\n",
    "    gold_df (DataFrame): Gold Excel DataFrame (will have more rows)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (results_df, summary_df) - DataFrames with comparison results and summary\n",
    "    \"\"\"\n",
    "    # Function to extract INSTRUMENT_ID from filepath\n",
    "    def extract_instrument_id(filepath):\n",
    "        # Extract the filename without extension\n",
    "        filename = os.path.basename(filepath)\n",
    "        # Remove file extension and '_f' suffix\n",
    "        instrument_id = filename.split('_')[0]\n",
    "        return instrument_id\n",
    "    \n",
    "    # Function to construct MICR code from Gold Excel\n",
    "    def construct_micr_code(row):\n",
    "        \"\"\"\n",
    "        Construct MICR code by concatenating specified fields from Gold Excel\n",
    "        Skip SCAN_MICR_ACNO if it's 0\n",
    "        \"\"\"\n",
    "        components = []\n",
    "        \n",
    "        # Add components only if they exist and are not null\n",
    "        if pd.notna(row['SCAN_INSTRUMENT_NUMBER']):\n",
    "            components.append(str(row['SCAN_INSTRUMENT_NUMBER']))\n",
    "        \n",
    "        if pd.notna(row['SCAN_PAYEE_BANK_CITY_CODE']):\n",
    "            components.append(str(row['SCAN_PAYEE_BANK_CITY_CODE']))\n",
    "            \n",
    "        if pd.notna(row['SCAN_PAYEE_BANK_CODE']):\n",
    "            components.append(str(row['SCAN_PAYEE_BANK_CODE']))\n",
    "            \n",
    "        if pd.notna(row['SCAN_PAYEE_BANK_BRANCH_CODE']):\n",
    "            components.append(str(row['SCAN_PAYEE_BANK_BRANCH_CODE']))\n",
    "        \n",
    "        # Only add SCAN_MICR_ACNO if it's not 0\n",
    "        if pd.notna(row['SCAN_MICR_ACNO']) and row['SCAN_MICR_ACNO'] != 0:\n",
    "            components.append(str(row['SCAN_MICR_ACNO']))\n",
    "            \n",
    "        if pd.notna(row['SCAN_INSTRUMENT_TYPE']):\n",
    "            components.append(str(row['SCAN_INSTRUMENT_TYPE']))\n",
    "        \n",
    "        return ''.join(components)\n",
    "    \n",
    "    # Function to normalize text for comparison\n",
    "    def normalize_text(text):\n",
    "        \"\"\"\n",
    "        Normalize text by removing leading/trailing spaces, converting to lowercase,\n",
    "        and removing special characters\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to string if not already\n",
    "        text = str(text)\n",
    "        \n",
    "        # Convert to lowercase and remove leading/trailing whitespace\n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    # Function to compare amounts with proper handling of decimal formats\n",
    "    def compare_amounts(amount1, amount2):\n",
    "        \"\"\"\n",
    "        Compare two amounts, handling different decimal formats\n",
    "        \"\"\"\n",
    "        # Handle NaN values\n",
    "        if pd.isna(amount1) or pd.isna(amount2):\n",
    "            return pd.isna(amount1) and pd.isna(amount2)\n",
    "        \n",
    "        # Convert to float for comparison\n",
    "        try:\n",
    "            float_amount1 = float(amount1)\n",
    "            float_amount2 = float(amount2)\n",
    "            \n",
    "            # Compare with a small tolerance for floating point errors\n",
    "            return abs(float_amount1 - float_amount2) < 1e-6\n",
    "        except (ValueError, TypeError):\n",
    "            # If conversion fails, compare as strings\n",
    "            return str(amount1) == str(amount2)\n",
    "    \n",
    "    print(\"Processing and comparing Excel files...\")\n",
    "    \n",
    "    # Extract INSTRUMENT_ID from filepath in extract_df\n",
    "    extract_df['extracted_instrument_id'] = extract_df['filepath'].apply(extract_instrument_id)\n",
    "    \n",
    "    # Construct MICR code in gold_df\n",
    "    gold_df['constructed_micr_code'] = gold_df.apply(construct_micr_code, axis=1)\n",
    "    \n",
    "    # Create a results DataFrame\n",
    "    results = []\n",
    "    \n",
    "    # Track overall matches\n",
    "    total_records = len(extract_df)\n",
    "    matched_records = 0\n",
    "    \n",
    "    # Track field-specific matches\n",
    "    instrument_id_matches = 0\n",
    "    micr_code_matches = 0\n",
    "    payee_name_matches = 0\n",
    "    amount_matches = 0\n",
    "    \n",
    "    # Print row counts to verify\n",
    "    print(f\"Extract Excel row count: {len(extract_df)}\")\n",
    "    print(f\"Gold Excel row count: {len(gold_df)}\")\n",
    "    print(f\"Note: Extract Excel has fewer rows as expected\")\n",
    "    \n",
    "    # Compare each record in extract_df with corresponding record in gold_df\n",
    "    for _, extract_row in extract_df.iterrows():\n",
    "        extract_instrument_id = extract_row['extracted_instrument_id']\n",
    "        \n",
    "        # Find matching row in gold_df\n",
    "        matching_gold_rows = gold_df[gold_df['INSTRUMENT_ID'] == extract_instrument_id]\n",
    "        \n",
    "        if len(matching_gold_rows) > 0:\n",
    "            # Match found\n",
    "            gold_row = matching_gold_rows.iloc[0]\n",
    "            \n",
    "            # Compare individual fields\n",
    "            # 1. INSTRUMENT_ID match\n",
    "            instrument_id_match = extract_instrument_id == gold_row['INSTRUMENT_ID']\n",
    "            if instrument_id_match:\n",
    "                instrument_id_matches += 1\n",
    "            \n",
    "            # 2. MICR code match\n",
    "            micr_code_match = extract_row['micr_code'] == gold_row['constructed_micr_code']\n",
    "            if micr_code_match:\n",
    "                micr_code_matches += 1\n",
    "            \n",
    "            # 3. Payee name match (normalized)\n",
    "            normalized_extract_payee = normalize_text(extract_row['payee_name'])\n",
    "            normalized_gold_payee = normalize_text(gold_row['PRES_NAME'])\n",
    "            payee_name_match = normalized_extract_payee == normalized_gold_payee\n",
    "            if payee_name_match:\n",
    "                payee_name_matches += 1\n",
    "            \n",
    "            # 4. Amount match\n",
    "            amount_match = compare_amounts(extract_row['amount_numeric'], gold_row['CAR_AMOUNT'])\n",
    "            if amount_match:\n",
    "                amount_matches += 1\n",
    "            \n",
    "            # Calculate overall match for this record\n",
    "            field_matches = [instrument_id_match, micr_code_match, payee_name_match, amount_match]\n",
    "            record_match_percentage = sum(field_matches) / len(field_matches) * 100\n",
    "            \n",
    "            # If all fields match, increment matched_records\n",
    "            if all(field_matches):\n",
    "                matched_records += 1\n",
    "            \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                'Extract_Filepath': extract_row['filepath'],\n",
    "                'Extract_Instrument_ID': extract_instrument_id,\n",
    "                'Gold_Instrument_ID': gold_row['INSTRUMENT_ID'],\n",
    "                'Extract_MICR_Code': extract_row['micr_code'],\n",
    "                'Gold_MICR_Code': gold_row['constructed_micr_code'],\n",
    "                'MICR_Code_Match': micr_code_match,\n",
    "                'Extract_Payee_Name': extract_row['payee_name'],\n",
    "                'Gold_Payee_Name': gold_row['PRES_NAME'],\n",
    "                'Payee_Name_Match': payee_name_match,\n",
    "                'Extract_Amount': extract_row['amount_numeric'],\n",
    "                'Gold_Amount': gold_row['CAR_AMOUNT'],\n",
    "                'Amount_Match': amount_match,\n",
    "                'Record_Match_Percentage': record_match_percentage\n",
    "            })\n",
    "        else:\n",
    "            # No match found\n",
    "            results.append({\n",
    "                'Extract_Filepath': extract_row['filepath'],\n",
    "                'Extract_Instrument_ID': extract_instrument_id,\n",
    "                'Gold_Instrument_ID': 'No match found',\n",
    "                'Extract_MICR_Code': extract_row['micr_code'],\n",
    "                'Gold_MICR_Code': 'No match found',\n",
    "                'MICR_Code_Match': False,\n",
    "                'Extract_Payee_Name': extract_row['payee_name'],\n",
    "                'Gold_Payee_Name': 'No match found',\n",
    "                'Payee_Name_Match': False,\n",
    "                'Extract_Amount': extract_row['amount_numeric'],\n",
    "                'Gold_Amount': 'No match found',\n",
    "                'Amount_Match': False,\n",
    "                'Record_Match_Percentage': 0.0\n",
    "            })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate overall match percentages\n",
    "    if total_records > 0:\n",
    "        overall_match_percentage = (matched_records / total_records) * 100\n",
    "        instrument_id_match_percentage = (instrument_id_matches / total_records) * 100\n",
    "        micr_code_match_percentage = (micr_code_matches / total_records) * 100\n",
    "        payee_name_match_percentage = (payee_name_matches / total_records) * 100\n",
    "        amount_match_percentage = (amount_matches / total_records) * 100\n",
    "    else:\n",
    "        overall_match_percentage = 0\n",
    "        instrument_id_match_percentage = 0\n",
    "        micr_code_match_percentage = 0\n",
    "        payee_name_match_percentage = 0\n",
    "        amount_match_percentage = 0\n",
    "    \n",
    "    # Add summary statistics\n",
    "    summary_df = pd.DataFrame([{\n",
    "        'Metric': 'Overall Match',\n",
    "        'Match_Percentage': overall_match_percentage,\n",
    "        'Matched_Count': matched_records,\n",
    "        'Total_Count': total_records\n",
    "    }, {\n",
    "        'Metric': 'Instrument ID Match',\n",
    "        'Match_Percentage': instrument_id_match_percentage,\n",
    "        'Matched_Count': instrument_id_matches,\n",
    "        'Total_Count': total_records\n",
    "    }, {\n",
    "        'Metric': 'MICR Code Match',\n",
    "        'Match_Percentage': micr_code_match_percentage,\n",
    "        'Matched_Count': micr_code_matches,\n",
    "        'Total_Count': total_records\n",
    "    }, {\n",
    "        'Metric': 'Payee Name Match',\n",
    "        'Match_Percentage': payee_name_match_percentage,\n",
    "        'Matched_Count': payee_name_matches,\n",
    "        'Total_Count': total_records\n",
    "    }, {\n",
    "        'Metric': 'Amount Match',\n",
    "        'Match_Percentage': amount_match_percentage,\n",
    "        'Matched_Count': amount_matches,\n",
    "        'Total_Count': total_records\n",
    "    }])\n",
    "    \n",
    "    return results_df, summary_df\n",
    "\n",
    "# 3. Save results to Excel\n",
    "def save_results(results_df, summary_df, output_path):\n",
    "    \"\"\"\n",
    "    Save comparison results to Excel file\n",
    "    \n",
    "    Parameters:\n",
    "    results_df (DataFrame): Detailed comparison results\n",
    "    summary_df (DataFrame): Summary statistics\n",
    "    output_path (str): Path to save output Excel\n",
    "    \n",
    "    Returns:\n",
    "    str: Path to saved Excel file\n",
    "    \"\"\"\n",
    "    print(f\"Saving results to {output_path}...\")\n",
    "    \n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        # Write detailed results to first sheet\n",
    "        results_df.to_excel(writer, sheet_name='Detailed Results', index=False)\n",
    "        \n",
    "        # Write summary to second sheet\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# 4. Main function to run the entire process\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Excel comparison process\n",
    "    \"\"\"\n",
    "    # Define file paths (update these to your actual file paths)\n",
    "    extract_file_path = \"extract.xlsx\"  # The extract Excel (with fewer rows)\n",
    "    gold_file_path = \"gold.xlsx\"        # The gold Excel (with more rows)\n",
    "    output_path = \"excel_comparison_results.xlsx\"\n",
    "    \n",
    "    # Load Excel files\n",
    "    extract_df, gold_df = load_excel_files(extract_file_path, gold_file_path)\n",
    "    \n",
    "    # Process and compare Excel files\n",
    "    results_df, summary_df = process_and_compare(extract_df, gold_df)\n",
    "    \n",
    "    # Save results\n",
    "    save_results(results_df, summary_df, output_path)\n",
    "    \n",
    "    print(\"Comparison completed successfully!\")\n",
    "    print(f\"Overall match percentage: {summary_df.loc[0, 'Match_Percentage']:.2f}%\")\n",
    "    \n",
    "    return results_df, summary_df\n",
    "\n",
    "# Run the comparison if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    results_df, summary_df = main()\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
